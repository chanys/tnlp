task: sequence_classification

model:
    model_id: distilbert-base-uncased
    tokenizer_id: distilbert-base-uncased

hyperparams:
    batch_size: 16
    gradient_accumulation_steps: 1
    epoch: 2
    learning_rate: 0.00001
    warmup_steps: 0
    save_steps: 10000
    save_total_limit: 0

processing:
    output_dir: /home/chanys/tnlp/expts/emotion_classification
    seed: 42

data:
    train_jsonl: /home/chanys/tnlp/data/emotion/train.jsonl
    validation_jsonl: /home/chanys/tnlp/data/emotion/validation.jsonl
    test_jsonl: /home/chanys/tnlp/data/emotion/test.jsonl
    inference_jsonl: /home/chanys/tnlp/data/emotion/inference.jsonl