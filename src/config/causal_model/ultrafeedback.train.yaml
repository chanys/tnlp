task: dpo_ft

model:
    model_id: BASE_DIR/expts/ultrachat_merged_model
    tokenizer_id: BASE_DIR/expts/ultrachat_sft

hyperparams:
    per_device_eval_batch_size: 4
    per_device_train_batch_size: 8
    gradient_accumulation_steps: 1
    epoch: 1
    learning_rate: 0.0000005
    warmup_steps: 0
    save_steps: 10000
    save_total_limit: 0
    max_seq_length: 512
    max_prompt_length: 256

lora:
    r: 16
    alpha: 16
    target_modules:
        - q_proj
        - k_proj
        - v_proj
        - o_proj
    task_type: CAUSAL_LM

processing:
    output_dir: BASE_DIR/expts/ultrafeedback_dpo
    seed: 42

data:
    train_jsonl: BASE_DIR/data/ultrafeedback/train_prefs.jsonl
    validation_jsonl: BASE_DIR/data/ultrafeedback/test_prefs.jsonl

